<!DOCTYPE html>
<html>
<head>
    <title></title>
    <style>
        body {
            font-family: "Times New Roman", Times, serif;
            margin: 50px;
            text-align: center;
            background-color: #d6ecf3;
        }
        img {
            height: auto;
            width: 200px;
        }
    </style>
</head>
<body>
    <h1>Project 5A: The Power of Diffusion Models!</h1>
    
    <h2>Part 0: </h2>
    <p>I used DeepFloyd's stage_1 and stage_2 objects for generation. The seed I used was 180.</p>
    <p>'an oil painting of a snowy mountain village': the output from stage1 is small and thus blurry while the output from stage2 is bigger and more clear. It does show a snowy village. However, it does not look like an oil painting.</p>
    <img src="media/snow1.png" style="display:inline-block;">
    <img src="media/snow2.png" style="display:inline-block;">
    <p>'a man wearing a hat': the output does show a man wearing a hat, but the man's eyes are not proper generated, and the background is just grey. But overall, the quality is good.</p>
    <img src="media/hat1.png" style="display:inline-block;">
    <img src="media/hat2.png" style="display:inline-block;">
    <p>'a rocket ship': the output is an animated rocket ship.</p>
    <img src="media/rocket1.png" style="display:inline-block;">
    <img src="media/rocket2.png" style="display:inline-block;">

    <p>I changed the num_inference_steps for 'a man wearing a hat': </p>
    <p>num_inference_steps=5: The process was indeed faster, but the quality was not as good. In this newly generate image, we could barely see the hat.</p>
    <img src="media/hat2.png" style="display:inline-block;">
    <img src="media/hat4.png" style="display:inline-block;">
    <p>num_inference_steps=80: The process was much slower. The output image has a more realistic background, and the man's gesture looks more natural.</p>
    <img src="media/hat2.png" style="display:inline-block;">
    <img src="media/hat6.png" style="display:inline-block;">


    <h2>Part 1.1: Implementing the forward process</h2>
    <p>I used the equation below to calculate a noisy image x_t at timestep t.</p>
    <img src="media/equation1.png">
    <p>Here's the original image:</p>
    <img src="media/test.png">
    <p>Here are the images at noise level 250, 500, 750. The image becomes noiser as the noise level increases.</p>
    <img src="media/forward1.png" style="display:inline-block;">
    <img src="media/forward2.png" style="display:inline-block;">
    <img src="media/forward3.png" style="display:inline-block;">

    <h2>Part 1.2: Classical Denoising</h2>
    <p>Below are the images at noise level 250, 500, 750:</p>
    <img src="media/forward1.png" style="display:inline-block;">
    <img src="media/forward2.png" style="display:inline-block;">
    <img src="media/forward3.png" style="display:inline-block;">
    <p>Below are the images that used Gaussian blur filtering to try to remove the noise: I used torchvision.transforms.functional.gaussian_blur.</p>
    <img src="media/gaussian1.png" style="display:inline-block;">
    <img src="media/gaussian2.png" style="display:inline-block;">
    <img src="media/gaussian3.png" style="display:inline-block;">

    <h2>Part 1.3: Implementing One Step Denoising</h2>
    <p>Below are the noisy images at noise level 250, 500, 750:</p>
    <img src="media/forward1.png" style="display:inline-block;">
    <img src="media/forward2.png" style="display:inline-block;">
    <img src="media/forward3.png" style="display:inline-block;">
    <p>Below are the images that used one-step denoising: I first used UNet to estimate the noise. Then I used the equation from above to predict x0 from xt and t.</p>
    <img src="media/onestep1.png" style="display:inline-block;">
    <img src="media/onestep2.png" style="display:inline-block;">
    <img src="media/onestep3.png" style="display:inline-block;">

    <h2>Part 1.4: Implementing Iterative Denoising</h2>
    <p>I first created a list of strided timesteps, which was a list of monotonically decreasing timesteps, starting at 990, with a stride of 30, eventually reaching 0. Then I used the formula below to iteratively calculate x at the next timestep. Eventually, the image went from from more noisy to less noisy.</p>
    <img src="media/equation2.png">
    <p>Below are the noisy images at noise level 90, 240, 390, 540, 690: </p>
    <img src="media/iterative1.png" style="display:inline-block;">
    <img src="media/iterative2.png" style="display:inline-block;">
    <img src="media/iterative3.png" style="display:inline-block;">
    <img src="media/iterative4.png" style="display:inline-block;">
    <img src="media/iterative5.png" style="display:inline-block;">
    <p>Below are the original image, iteratively denoised image, one-step denoised image, and gaussian blurred image:</p>
    <img src="media/test.png" style="display:inline-block;">
    <img src="media/iterative.png" style="display:inline-block;">
    <img src="media/iterative_onestep.png" style="display:inline-block;">
    <img src="media/iterative_gaussian.png" style="display:inline-block;">

    <h2>Part 1.5: Diffusion Model Sampling</h2>
    <p>Here are 5 sampled images by using the iterative_denoise function from previous section and setting i_start = 0:</p>
    <img src="media/sample1.png" style="display:inline-block;">
    <img src="media/sample2.png" style="display:inline-block;">
    <img src="media/sample3.png" style="display:inline-block;">
    <img src="media/sample4.png" style="display:inline-block;">
    <img src="media/sample5.png" style="display:inline-block;">

    <h2>Part 1.6: Classifier Free Guidance</h2>
    <p>By using CFG, I computed both a conditional and an unconditional noise estimate. The new noise estimate is thus provided by the equation below.</p>
    <img src="media/equation3.png">
    <p>Here are 5 sampled images using CFG with ùõæ=7:</p>
    <img src="media/sample11.png" style="display:inline-block;">
    <img src="media/sample22.png" style="display:inline-block;">
    <img src="media/sample33.png" style="display:inline-block;">
    <img src="media/sample44.png" style="display:inline-block;">
    <img src="media/sample55.png" style="display:inline-block;">

    <h2>Part 1.7: Image-to-image Translation</h2>
    <p>I started with a noisy image, then I set different start of the noise levels. As the start of the noise level increases, it matches the original image closer.</p>
    <p>Test Image</p>
    <img src="media/test.png" style="display:inline-block;">
    <p>Here are the edits of the test image at noise levels 1, 3, 5, 7, 10, 20: They gradually match the original image closer and closer.</p>
    <img src="media/edit1.png" style="display:inline-block;">
    <img src="media/edit2.png" style="display:inline-block;">
    <img src="media/edit3.png" style="display:inline-block;">
    <img src="media/edit4.png" style="display:inline-block;">
    <img src="media/edit5.png" style="display:inline-block;">
    <img src="media/edit6.png" style="display:inline-block;">
    <p>My Test Image 1</p>
    <img src="media/test1.png" style="display:inline-block;">
    <p>Here are the edits of my test image 1 at noise levels 1, 3, 5, 7, 10, 20: </p>
    <img src="media/edit11.png" style="display:inline-block;">
    <img src="media/edit22.png" style="display:inline-block;">
    <img src="media/edit33.png" style="display:inline-block;">
    <img src="media/edit44.png" style="display:inline-block;">
    <img src="media/edit55.png" style="display:inline-block;">
    <img src="media/edit66.png" style="display:inline-block;">
    <p>My Test Image 2</p>
    <img src="media/test2.png" style="display:inline-block;">
    <p>Here are the edits of my test image 2 at noise levels 1, 3, 5, 7, 10, 20: </p>
    <img src="media/edit111.png" style="display:inline-block;">
    <img src="media/edit222.png" style="display:inline-block;">
    <img src="media/edit333.png" style="display:inline-block;">
    <img src="media/edit444.png" style="display:inline-block;">
    <img src="media/edit555.png" style="display:inline-block;">
    <img src="media/edit666.png" style="display:inline-block;">

    <h2>Part 1.7.1: Editing Hand-Drawn and Web Images</h2>
    <p>For the painted image, it overall matches the original image better than the drawn images.</p>
    <p>For my drawn images, when i_start is small, the generated images are not relevant at all. But when i_start is at 10, 20, 30, it matches closer.</p>
    <p>Here's a painted image from the web:</p>
    <img src="media/web.png" style="display:inline-block;">
    <p>Here are the edits of this web image at noise levels 1, 3, 5, 7, 10, 20: </p>
    <img src="media/web1.png" style="display:inline-block;">
    <img src="media/web2.png" style="display:inline-block;">
    <img src="media/web3.png" style="display:inline-block;">
    <img src="media/web4.png" style="display:inline-block;">
    <img src="media/web5.png" style="display:inline-block;">
    <img src="media/web6.png" style="display:inline-block;">

    <p>Here's a drawn image: I drew a tree.</p>
    <img src="media/tree.png" style="display:inline-block;">
    <p>Here are the edits of this drawn image at noise levels 1, 3, 5, 7, 10, 20, 30: </p>
    <img src="media/tree1.png" style="display:inline-block;">
    <img src="media/tree2.png" style="display:inline-block;">
    <img src="media/tree3.png" style="display:inline-block;">
    <img src="media/tree4.png" style="display:inline-block;">
    <img src="media/tree5.png" style="display:inline-block;">
    <img src="media/tree6.png" style="display:inline-block;">
    <img src="media/tree7.png" style="display:inline-block;">

    <p>Here's another drawn image: I drew a bird.</p>
    <img src="media/bird.png" style="display:inline-block;">
    <p>Here are the edits of this drawn image at noise levels 1, 3, 5, 7, 10, 20, 30: </p>
    <img src="media/bird1.png" style="display:inline-block;">
    <img src="media/bird2.png" style="display:inline-block;">
    <img src="media/bird3.png" style="display:inline-block;">
    <img src="media/bird4.png" style="display:inline-block;">
    <img src="media/bird5.png" style="display:inline-block;">
    <img src="media/bird6.png" style="display:inline-block;">
    <img src="media/bird7.png" style="display:inline-block;">


    <h2>Part 1.7.2: Inpainting</h2>
    <p>To inpaint, I used a binary mask. The generated image has same content where mask m is 0 but new content wherever mask m is 1.</p>
    <img src="media/equation4.png">
    <p>Here's the test image inpainted:</p>
    <img src="media/test.png" style="display:inline-block;">
    <img src="media/mask.png" style="display:inline-block;">
    <img src="media/replace.png" style="display:inline-block;">
    <img src="media/inpaint.png" style="display:inline-block;">
    <p>Here's my test image 1 inpainted:</p>
    <img src="media/test1.png" style="display:inline-block;">
    <img src="media/mask1.png" style="display:inline-block;">
    <img src="media/replace1.png" style="display:inline-block;">
    <img src="media/inpaint1.png" style="display:inline-block;">
    <p>Here's my test image 2 inpainted:</p>
    <img src="media/test2.png" style="display:inline-block;">
    <img src="media/mask2.png" style="display:inline-block;">
    <img src="media/replace2.png" style="display:inline-block;">
    <img src="media/inpaint2.png" style="display:inline-block;">

    <h2>Part 1.7.3: Text-Conditional Image-to-image Translation</h2>
    <p>The images gradually look more like original image as the noise level increases, but they also look somewhat like the text prompt.</p>
    <p>Here are the edits of the test image at noise levels 1, 3, 5, 7, 10, 20 with the prompt "a rocket ship"</p>
    <img src="media/rocket_test1.png" style="display:inline-block;">
    <img src="media/rocket_test2.png" style="display:inline-block;">
    <img src="media/rocket_test3.png" style="display:inline-block;">
    <img src="media/rocket_test4.png" style="display:inline-block;">
    <img src="media/rocket_test5.png" style="display:inline-block;">
    <img src="media/rocket_test6.png" style="display:inline-block;">
    <p>Here are the edits of my test image 1 at noise levels 1, 3, 5, 7, 10, 20 with the prompt "an oil painting of a snowy mountain village"</p>
    <img src="media/snow_test1.png" style="display:inline-block;">
    <img src="media/snow_test2.png" style="display:inline-block;">
    <img src="media/snow_test3.png" style="display:inline-block;">
    <img src="media/snow_test4.png" style="display:inline-block;">
    <img src="media/snow_test5.png" style="display:inline-block;">
    <img src="media/snow_test6.png" style="display:inline-block;">
    <p>Here are the edits of my test image 2 at noise levels 1, 3, 5, 7, 10, 20 with the prompt "a man wearing a hat"</p>
    <img src="media/hat_test1.png" style="display:inline-block;">
    <img src="media/hat_test2.png" style="display:inline-block;">
    <img src="media/hat_test3.png" style="display:inline-block;">
    <img src="media/hat_test4.png" style="display:inline-block;">
    <img src="media/hat_test5.png" style="display:inline-block;">
    <img src="media/hat_test6.png" style="display:inline-block;">


    <h2>Part 1.8: Visual Anagrams</h2>
    <p>I used the following algorithm to obtain the visual anagrams, where p1 and p2 are two different text prompt embeddings, flip() is a function that flips the image top to bottom. </p>
    <img src="media/equation5.png">
    <p>Here's a visual anagram where on one orientation "an oil painting of people around a campfire" is displayed and, when flipped, "an oil painting of an old man" is displayed.</p>
    <img src="media/campfire.png" style="display:inline-block;">
    <img src="media/oldman.png" style="display:inline-block;">
    <p>Here's a visual anagram where on one orientation "an oil painting of a snowy mountain village" is displayed and, when flipped, "a photo of the amalfi coast" is displayed.</p>
    <img src="media/mountain.png" style="display:inline-block;">
    <img src="media/coast.png" style="display:inline-block;">
    <p>Here's a visual anagram where on one orientation "a lithograph of waterfalls" is displayed and, when flipped, "a photo of dog" is displayed.</p>
    <img src="media/waterfall.png" style="display:inline-block;">
    <img src="media/dog.png" style="display:inline-block;">


    <h2>Part 1.9: Hybrid Images</h2>
    <p>I used the algorithm below: first use the diffusion model over p1 and p2, which are 2 different text prompt embeddings. Then lowpass the first noise estimate and highpass the second noise estimate. So we get an image that looks like one thing from far away but another object from close up.</p>
    <img src="media/equation6.png">
    <p>Here's an image that looks like a skull from far away but a waterfall from close up.</p>
    <img src="media/skull_waterfall.png" style="display:inline-block;">
    <p>Here's an image that looks like a man from far away but a snowy mountain village from close up.</p>
    <img src="media/man_snow.png" style="display:inline-block;">
    <p>Here's an image that looks like a rocket ship from far away but a dog from close up.</p>
    <img src="media/rocket_dog.png" style="display:inline-block;">


    <h1>Project 5B: Diffusion Models from Scratch!</h1>
    
    <h2>Part 1: Training a Single-Step Denoising UNet</h2>
    <p>A visualization of the noising process using 0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0:</p>
    <img src="media/noiselevels.png" style="display:inline-block;">
    <p>A training loss curve plot every few iterations during the whole training process:</p>
    <img src="media/losscurve.png" style="display:inline-block;">
    <p>Sample results on the test set after the first epoch: from top to bottom, the images show the input, the noisy image with noise level = 0.5, and the output.</p>
    <img src="media/first1.png" style="display:inline-block;">
    <img src="media/first2.png" style="display:inline-block;">
    <img src="media/first3.png" style="display:inline-block;">
    <p>Sample results on the test set after the 5th epoch:</p>
    <img src="media/fifth1.png" style="display:inline-block;">
    <img src="media/fifth2.png" style="display:inline-block;">
    <img src="media/fifth3.png" style="display:inline-block;">
    <p>Sample results on the test set with out-of-distribution noise levels after the model is trained: from left to right are noise level 0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0. The images on top are noisy images while the ones on the bottom are denoised outputs.</p>
    <img src="media/ood1.png" style="display:inline-block;">
    <img src="media/ood2.png" style="display:inline-block;">
    <img src="media/ood3.png" style="display:inline-block;">
    <img src="media/ood4.png" style="display:inline-block;">
    <img src="media/ood5.png" style="display:inline-block;">
    <img src="media/ood6.png" style="display:inline-block;">
    <img src="media/ood7.png" style="display:inline-block;">


    <h2>Part 2: Training a Diffusion Model</h2>
    <h3>Implementing a Time-conditioned UNet</h3>
    <p>Training loss curve plot over the whole training process:</p>
    <img src="media/losscurve1.png" style="display:inline-block;">
    <p>Sampling results for the time-conditioned UNet for 5 epochs.</p>
    <img src="media/time5.png" style="display:inline-block;">
    <p>Sampling results for the time-conditioned UNet for 20 epochs.</p>
    <img src="media/time20.png" style="display:inline-block;">


    <h3>Implementing class-conditioned UNet</h3>
    <p>A training loss curve plot for the class-conditioned UNet over the whole training process:</p>
    <img src="media/losscurve2.png" style="display:inline-block;">
    <p>Sampling results for the class-conditioned UNet for 5 epochs</p>
    <img src="media/class5.png" style="display:inline-block;">
    <img src="media/class55.png" style="display:inline-block;">
    <img src="media/class555.png" style="display:inline-block;">
    <img src="media/class5555.png" style="display:inline-block;">
    <p>Sampling results for the class-conditioned UNet for 20 epochs</p>
    <img src="media/class20.png" style="display:inline-block;">
    <img src="media/class2020.png" style="display:inline-block;">
    <img src="media/class202020.png" style="display:inline-block;">
    <img src="media/class20202020.png" style="display:inline-block;">


</body>
</html>
